{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers 모듈 설치\n",
    "# pip install transformers\n",
    "# google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0552b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45daad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641735de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected remote with confidence 0.998 at location [40.16, 70.81, 175.55, 117.98]\n",
      "Detected remote with confidence 0.996 at location [333.24, 72.55, 368.33, 187.66]\n",
      "Detected couch with confidence 0.995 at location [-0.02, 1.15, 639.73, 473.76]\n",
      "Detected cat with confidence 0.999 at location [13.24, 52.05, 314.02, 470.93]\n",
      "Detected cat with confidence 0.999 at location [345.4, 23.85, 640.37, 368.72]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# you can specify the revision tag if you don't want the timm dependency\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia/segformer-b0-finetuned-ade-512-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a7b7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0687839bea894647ae15b79db9b3cc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201-11\\.conda\\envs\\himedia\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\201-11\\.cache\\huggingface\\hub\\models--nvidia--segformer-b0-finetuned-ade-512-512. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\201-11\\.conda\\envs\\himedia\\lib\\site-packages\\transformers\\utils\\deprecation.py:165: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1ba2c8a928467b88eed1f02d62ed7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/6.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44834232be6e47888b99875ec4675344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/15.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34ecd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -4.6310,  -5.5232,  -6.2356,  ...,  -4.9868,  -4.7341,  -4.6612],\n",
       "          [ -5.1921,  -6.1444,  -6.5996,  ...,  -5.1771,  -5.0288,  -5.1761],\n",
       "          [ -5.4424,  -6.2790,  -6.7574,  ...,  -5.2748,  -5.1669,  -5.0999],\n",
       "          ...,\n",
       "          [ -8.5836,  -9.0887,  -9.5409,  ...,  -8.7190,  -8.5183,  -8.3098],\n",
       "          [ -8.4320,  -8.8555,  -9.1848,  ...,  -7.7831,  -7.4822,  -7.3598],\n",
       "          [ -8.3224,  -8.8764,  -9.1849,  ...,  -7.1564,  -6.8759,  -6.6428]],\n",
       "\n",
       "         [[-12.1391, -13.3122, -13.9554,  ..., -11.8693, -11.5761, -11.3418],\n",
       "          [-12.8732, -13.9352, -14.3563,  ..., -12.3348, -12.1524, -12.3176],\n",
       "          [-12.9438, -13.8226, -14.2513,  ..., -12.3360, -12.3081, -12.2396],\n",
       "          ...,\n",
       "          [-13.9108, -14.2715, -14.6169,  ..., -13.2829, -13.3424, -13.3222],\n",
       "          [-13.8718, -14.2715, -14.3808,  ..., -12.5270, -12.4334, -12.3057],\n",
       "          [-13.6848, -14.2857, -14.5154,  ..., -11.8523, -11.8534, -11.6054]],\n",
       "\n",
       "         [[-12.5134, -13.4687, -14.4915,  ..., -14.7524, -14.6752, -14.7539],\n",
       "          [-12.8669, -14.4343, -14.7759,  ..., -15.5266, -15.2715, -15.6948],\n",
       "          [-13.2523, -14.5819, -15.0694,  ..., -15.1948, -15.1842, -15.2351],\n",
       "          ...,\n",
       "          [-12.4332, -13.8369, -13.9595,  ..., -11.1260, -10.5045, -10.7628],\n",
       "          [-12.4539, -13.5327, -13.4623,  ...,  -9.4442,  -9.6495,  -9.9279],\n",
       "          [-12.0739, -13.7770, -13.3864,  ...,  -9.1082,  -9.0598,  -9.1622]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -9.8355, -11.1564, -11.5369,  ..., -10.7281, -10.6814, -10.6911],\n",
       "          [-10.5248, -12.0654, -11.9863,  ..., -10.7789, -10.7987, -11.2357],\n",
       "          [-10.6186, -11.7279, -11.8124,  ..., -10.4900, -10.5833, -10.5385],\n",
       "          ...,\n",
       "          [-13.5772, -14.0249, -14.4783,  ..., -10.4502, -10.7166, -10.6168],\n",
       "          [-13.3221, -13.8725, -14.0920,  ..., -10.1565,  -9.6386,  -9.6399],\n",
       "          [-12.9738, -13.6139, -14.1394,  ...,  -9.3478,  -9.5651,  -9.3483]],\n",
       "\n",
       "         [[-13.9001, -15.5144, -16.1385,  ..., -16.1757, -15.8854, -15.7593],\n",
       "          [-14.9662, -16.9494, -16.9131,  ..., -16.7597, -16.4398, -17.2087],\n",
       "          [-14.8009, -16.1647, -16.4558,  ..., -16.6088, -16.5134, -16.5198],\n",
       "          ...,\n",
       "          [-19.3070, -19.3882, -19.7165,  ..., -16.5413, -16.8963, -16.5222],\n",
       "          [-18.9477, -19.0455, -19.3182,  ..., -15.6801, -15.3118, -15.2232],\n",
       "          [-18.7540, -18.6521, -19.2379,  ..., -14.3307, -14.5261, -14.2830]],\n",
       "\n",
       "         [[-11.8252, -13.5153, -14.3746,  ..., -14.5415, -14.1839, -14.1570],\n",
       "          [-12.9569, -14.4699, -14.9125,  ..., -14.8898, -14.6202, -15.2587],\n",
       "          [-13.4182, -14.5278, -15.0841,  ..., -14.7970, -14.7258, -14.6893],\n",
       "          ...,\n",
       "          [-12.2241, -12.8770, -13.3283,  ..., -10.5530, -11.1294, -11.0255],\n",
       "          [-12.2176, -12.7628, -13.0899,  ..., -10.2068, -10.1131, -10.0624],\n",
       "          [-12.0882, -12.9164, -13.2079,  ...,  -9.4103,  -9.6375,  -9.4212]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c5a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 150, 128, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai-community/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7942b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb33f3cdca9f4d39bb8539fced1cdbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201-11\\.conda\\envs\\himedia\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\201-11\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231d4d354dd74509a6fd22f24cbe84a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f68ccf04a974e7c9ae2c108bcddd7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad65daef9ab94d9c93794d80c5ce4257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742946a31f5047ccba1bacb0b0b9a75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201-11\\.conda\\envs\\himedia\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42f0fb4a7ed49408244c19bb6ccc806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2Model.\n",
      "\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2Model.from_pretrained('gpt2')\n",
    "text = \"My name is AK47. I am \"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da88860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
